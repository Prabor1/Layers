# Layers_creation

Here I impilment my own custom layer. The layer is already available in Keras. I implimented Leaky ReLU using some basic tf libraries. The data is popular mnist data, which is available with tf. The utils file will import the data and do the preprocessing. It also consists some helper function. After training model with our layer, I compared my result with ReLU, which gives a good result with overall 97% acc on val set. Source code for python is available.
